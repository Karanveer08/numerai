{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "numerai_1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNHQyBZGo94p",
        "colab_type": "code",
        "outputId": "37fc6485-f626-4ac9-9286-9146edfd4839",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iLhpmhspFP1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root_path ='gdrive/My Drive/dataset1/numerai_training_data.csv'\n",
        "root_path ='gdrive/My Drive/dataset1/numerai_tournament_data.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bjbj8iwcpae9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bA5Q4Wzfpk3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_data = pd.read_csv('gdrive/My Drive/dataset1/numerai_training_data.csv',header=0)\n",
        "tournament_data =pd.read_csv('gdrive/My Drive/dataset1/numerai_tournament_data.csv',header=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RvjGJ2xpt6E",
        "colab_type": "code",
        "outputId": "b990c5e0-2355-4aa4-ac55-66e83b65d9c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "dataset = pd.read_csv('gdrive/My Drive/dataset1/numerai_training_data.csv')\n",
        "\n",
        "X = dataset.iloc[:56083,0:50].values\n",
        "y = dataset.iloc[:56083,50:].values\n",
        "\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "print(y)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(56083, 50)\n",
            "(56083, 10)\n",
            "[[0.55239 0.64054 0.52182 ... 1.      1.      1.     ]\n",
            " [0.46029 0.62941 0.5501  ... 1.      1.      1.     ]\n",
            " [0.40596 0.54731 0.39061 ... 0.      0.      0.     ]\n",
            " ...\n",
            " [0.72552 0.52737 0.55081 ... 0.      0.      0.     ]\n",
            " [0.72564 0.49359 0.37022 ... 1.      1.      1.     ]\n",
            " [0.62116 0.44767 0.54396 ... 1.      1.      1.     ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OLN0HAaqVZF",
        "colab_type": "code",
        "outputId": "da65310c-70c4-4f11-d4d7-30dc00b73fc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "training_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>era</th>\n",
              "      <th>data_type</th>\n",
              "      <th>feature1</th>\n",
              "      <th>feature2</th>\n",
              "      <th>feature3</th>\n",
              "      <th>feature4</th>\n",
              "      <th>feature5</th>\n",
              "      <th>feature6</th>\n",
              "      <th>feature7</th>\n",
              "      <th>feature8</th>\n",
              "      <th>feature9</th>\n",
              "      <th>feature10</th>\n",
              "      <th>feature11</th>\n",
              "      <th>feature12</th>\n",
              "      <th>feature13</th>\n",
              "      <th>feature14</th>\n",
              "      <th>feature15</th>\n",
              "      <th>feature16</th>\n",
              "      <th>feature17</th>\n",
              "      <th>feature18</th>\n",
              "      <th>feature19</th>\n",
              "      <th>feature20</th>\n",
              "      <th>feature21</th>\n",
              "      <th>feature22</th>\n",
              "      <th>feature23</th>\n",
              "      <th>feature24</th>\n",
              "      <th>feature25</th>\n",
              "      <th>feature26</th>\n",
              "      <th>feature27</th>\n",
              "      <th>feature28</th>\n",
              "      <th>feature29</th>\n",
              "      <th>feature30</th>\n",
              "      <th>feature31</th>\n",
              "      <th>feature32</th>\n",
              "      <th>feature33</th>\n",
              "      <th>feature34</th>\n",
              "      <th>feature35</th>\n",
              "      <th>feature36</th>\n",
              "      <th>feature37</th>\n",
              "      <th>feature38</th>\n",
              "      <th>feature39</th>\n",
              "      <th>feature40</th>\n",
              "      <th>feature41</th>\n",
              "      <th>feature42</th>\n",
              "      <th>feature43</th>\n",
              "      <th>feature44</th>\n",
              "      <th>feature45</th>\n",
              "      <th>feature46</th>\n",
              "      <th>feature47</th>\n",
              "      <th>feature48</th>\n",
              "      <th>feature49</th>\n",
              "      <th>feature50</th>\n",
              "      <th>target_bernie</th>\n",
              "      <th>target_elizabeth</th>\n",
              "      <th>target_jordan</th>\n",
              "      <th>target_ken</th>\n",
              "      <th>target_charles</th>\n",
              "      <th>target_frank</th>\n",
              "      <th>target_hillary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>n0003126ff2349f6</td>\n",
              "      <td>era1</td>\n",
              "      <td>train</td>\n",
              "      <td>0.54836</td>\n",
              "      <td>0.31077</td>\n",
              "      <td>0.37524</td>\n",
              "      <td>0.49490</td>\n",
              "      <td>0.53217</td>\n",
              "      <td>0.48388</td>\n",
              "      <td>0.50220</td>\n",
              "      <td>0.59506</td>\n",
              "      <td>0.55422</td>\n",
              "      <td>0.48578</td>\n",
              "      <td>0.59966</td>\n",
              "      <td>0.45133</td>\n",
              "      <td>0.46165</td>\n",
              "      <td>0.58824</td>\n",
              "      <td>0.47648</td>\n",
              "      <td>0.54185</td>\n",
              "      <td>0.53035</td>\n",
              "      <td>0.52805</td>\n",
              "      <td>0.62023</td>\n",
              "      <td>0.54217</td>\n",
              "      <td>0.70297</td>\n",
              "      <td>0.69448</td>\n",
              "      <td>0.46862</td>\n",
              "      <td>0.51515</td>\n",
              "      <td>0.44668</td>\n",
              "      <td>0.53039</td>\n",
              "      <td>0.58756</td>\n",
              "      <td>0.36058</td>\n",
              "      <td>0.41920</td>\n",
              "      <td>0.46516</td>\n",
              "      <td>0.53498</td>\n",
              "      <td>0.63175</td>\n",
              "      <td>0.53577</td>\n",
              "      <td>0.36623</td>\n",
              "      <td>0.37073</td>\n",
              "      <td>0.54078</td>\n",
              "      <td>0.58522</td>\n",
              "      <td>0.64636</td>\n",
              "      <td>0.60431</td>\n",
              "      <td>0.42239</td>\n",
              "      <td>0.67937</td>\n",
              "      <td>0.32205</td>\n",
              "      <td>0.53407</td>\n",
              "      <td>0.46254</td>\n",
              "      <td>0.56658</td>\n",
              "      <td>0.46022</td>\n",
              "      <td>0.63760</td>\n",
              "      <td>0.55239</td>\n",
              "      <td>0.64054</td>\n",
              "      <td>0.52182</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>n003d773d29b57ec</td>\n",
              "      <td>era1</td>\n",
              "      <td>train</td>\n",
              "      <td>0.34712</td>\n",
              "      <td>0.40275</td>\n",
              "      <td>0.42747</td>\n",
              "      <td>0.44006</td>\n",
              "      <td>0.47866</td>\n",
              "      <td>0.44055</td>\n",
              "      <td>0.59182</td>\n",
              "      <td>0.68856</td>\n",
              "      <td>0.56543</td>\n",
              "      <td>0.57715</td>\n",
              "      <td>0.57795</td>\n",
              "      <td>0.55753</td>\n",
              "      <td>0.48289</td>\n",
              "      <td>0.46031</td>\n",
              "      <td>0.50983</td>\n",
              "      <td>0.41775</td>\n",
              "      <td>0.51362</td>\n",
              "      <td>0.49862</td>\n",
              "      <td>0.39821</td>\n",
              "      <td>0.61058</td>\n",
              "      <td>0.49282</td>\n",
              "      <td>0.58034</td>\n",
              "      <td>0.52376</td>\n",
              "      <td>0.41882</td>\n",
              "      <td>0.62424</td>\n",
              "      <td>0.50778</td>\n",
              "      <td>0.29379</td>\n",
              "      <td>0.50027</td>\n",
              "      <td>0.45552</td>\n",
              "      <td>0.35620</td>\n",
              "      <td>0.49544</td>\n",
              "      <td>0.35277</td>\n",
              "      <td>0.59167</td>\n",
              "      <td>0.52869</td>\n",
              "      <td>0.65674</td>\n",
              "      <td>0.47519</td>\n",
              "      <td>0.60547</td>\n",
              "      <td>0.56362</td>\n",
              "      <td>0.38146</td>\n",
              "      <td>0.58835</td>\n",
              "      <td>0.65277</td>\n",
              "      <td>0.46215</td>\n",
              "      <td>0.48303</td>\n",
              "      <td>0.35919</td>\n",
              "      <td>0.58709</td>\n",
              "      <td>0.55369</td>\n",
              "      <td>0.64628</td>\n",
              "      <td>0.46029</td>\n",
              "      <td>0.62941</td>\n",
              "      <td>0.55010</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>n0074df2dc6810b6</td>\n",
              "      <td>era1</td>\n",
              "      <td>train</td>\n",
              "      <td>0.50871</td>\n",
              "      <td>0.48639</td>\n",
              "      <td>0.47544</td>\n",
              "      <td>0.40306</td>\n",
              "      <td>0.53436</td>\n",
              "      <td>0.64028</td>\n",
              "      <td>0.51420</td>\n",
              "      <td>0.63232</td>\n",
              "      <td>0.62101</td>\n",
              "      <td>0.48065</td>\n",
              "      <td>0.54203</td>\n",
              "      <td>0.55304</td>\n",
              "      <td>0.72525</td>\n",
              "      <td>0.57408</td>\n",
              "      <td>0.49368</td>\n",
              "      <td>0.41108</td>\n",
              "      <td>0.42165</td>\n",
              "      <td>0.41740</td>\n",
              "      <td>0.49350</td>\n",
              "      <td>0.41937</td>\n",
              "      <td>0.58758</td>\n",
              "      <td>0.40735</td>\n",
              "      <td>0.54397</td>\n",
              "      <td>0.49110</td>\n",
              "      <td>0.46319</td>\n",
              "      <td>0.47559</td>\n",
              "      <td>0.53655</td>\n",
              "      <td>0.33736</td>\n",
              "      <td>0.35971</td>\n",
              "      <td>0.57398</td>\n",
              "      <td>0.36414</td>\n",
              "      <td>0.44651</td>\n",
              "      <td>0.50714</td>\n",
              "      <td>0.53124</td>\n",
              "      <td>0.38978</td>\n",
              "      <td>0.54079</td>\n",
              "      <td>0.51058</td>\n",
              "      <td>0.54912</td>\n",
              "      <td>0.44611</td>\n",
              "      <td>0.41032</td>\n",
              "      <td>0.49190</td>\n",
              "      <td>0.50243</td>\n",
              "      <td>0.51624</td>\n",
              "      <td>0.48028</td>\n",
              "      <td>0.73195</td>\n",
              "      <td>0.42444</td>\n",
              "      <td>0.43228</td>\n",
              "      <td>0.40596</td>\n",
              "      <td>0.54731</td>\n",
              "      <td>0.39061</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>n0090630f530903e</td>\n",
              "      <td>era1</td>\n",
              "      <td>train</td>\n",
              "      <td>0.61363</td>\n",
              "      <td>0.40268</td>\n",
              "      <td>0.53779</td>\n",
              "      <td>0.37045</td>\n",
              "      <td>0.58711</td>\n",
              "      <td>0.59900</td>\n",
              "      <td>0.62428</td>\n",
              "      <td>0.73602</td>\n",
              "      <td>0.43887</td>\n",
              "      <td>0.28383</td>\n",
              "      <td>0.49202</td>\n",
              "      <td>0.54222</td>\n",
              "      <td>0.70992</td>\n",
              "      <td>0.26707</td>\n",
              "      <td>0.72053</td>\n",
              "      <td>0.54136</td>\n",
              "      <td>0.51821</td>\n",
              "      <td>0.56212</td>\n",
              "      <td>0.46081</td>\n",
              "      <td>0.62571</td>\n",
              "      <td>0.32497</td>\n",
              "      <td>0.64330</td>\n",
              "      <td>0.39063</td>\n",
              "      <td>0.32134</td>\n",
              "      <td>0.45451</td>\n",
              "      <td>0.58448</td>\n",
              "      <td>0.40316</td>\n",
              "      <td>0.51858</td>\n",
              "      <td>0.48830</td>\n",
              "      <td>0.45194</td>\n",
              "      <td>0.20134</td>\n",
              "      <td>0.50705</td>\n",
              "      <td>0.38831</td>\n",
              "      <td>0.35573</td>\n",
              "      <td>0.52929</td>\n",
              "      <td>0.52327</td>\n",
              "      <td>0.48866</td>\n",
              "      <td>0.42828</td>\n",
              "      <td>0.50020</td>\n",
              "      <td>0.37528</td>\n",
              "      <td>0.54360</td>\n",
              "      <td>0.54347</td>\n",
              "      <td>0.46995</td>\n",
              "      <td>0.60385</td>\n",
              "      <td>0.56471</td>\n",
              "      <td>0.51203</td>\n",
              "      <td>0.35597</td>\n",
              "      <td>0.53878</td>\n",
              "      <td>0.47776</td>\n",
              "      <td>0.36835</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>n00af19089546fe9</td>\n",
              "      <td>era1</td>\n",
              "      <td>train</td>\n",
              "      <td>0.30704</td>\n",
              "      <td>0.47273</td>\n",
              "      <td>0.54495</td>\n",
              "      <td>0.48692</td>\n",
              "      <td>0.47348</td>\n",
              "      <td>0.34695</td>\n",
              "      <td>0.41506</td>\n",
              "      <td>0.61225</td>\n",
              "      <td>0.56853</td>\n",
              "      <td>0.44104</td>\n",
              "      <td>0.45416</td>\n",
              "      <td>0.50839</td>\n",
              "      <td>0.40957</td>\n",
              "      <td>0.67414</td>\n",
              "      <td>0.45356</td>\n",
              "      <td>0.59333</td>\n",
              "      <td>0.50526</td>\n",
              "      <td>0.15084</td>\n",
              "      <td>0.40621</td>\n",
              "      <td>0.39427</td>\n",
              "      <td>0.66767</td>\n",
              "      <td>0.41428</td>\n",
              "      <td>0.52894</td>\n",
              "      <td>0.57846</td>\n",
              "      <td>0.58134</td>\n",
              "      <td>0.49488</td>\n",
              "      <td>0.56870</td>\n",
              "      <td>0.62991</td>\n",
              "      <td>0.45221</td>\n",
              "      <td>0.48362</td>\n",
              "      <td>0.71259</td>\n",
              "      <td>0.39272</td>\n",
              "      <td>0.70319</td>\n",
              "      <td>0.62108</td>\n",
              "      <td>0.49073</td>\n",
              "      <td>0.50437</td>\n",
              "      <td>0.36032</td>\n",
              "      <td>0.47219</td>\n",
              "      <td>0.46962</td>\n",
              "      <td>0.30812</td>\n",
              "      <td>0.71654</td>\n",
              "      <td>0.54050</td>\n",
              "      <td>0.39448</td>\n",
              "      <td>0.29495</td>\n",
              "      <td>0.61935</td>\n",
              "      <td>0.45651</td>\n",
              "      <td>0.53768</td>\n",
              "      <td>0.46431</td>\n",
              "      <td>0.49482</td>\n",
              "      <td>0.60452</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id   era  ... target_frank  target_hillary\n",
              "0  n0003126ff2349f6  era1  ...            1               1\n",
              "1  n003d773d29b57ec  era1  ...            1               1\n",
              "2  n0074df2dc6810b6  era1  ...            0               0\n",
              "3  n0090630f530903e  era1  ...            0               0\n",
              "4  n00af19089546fe9  era1  ...            1               1\n",
              "\n",
              "[5 rows x 60 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylduMQek7_BI",
        "colab_type": "code",
        "outputId": "07e34fdf-9d57-410e-84c1-eff140072ee4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "print(training_data.era.unique())\n",
        "print(training_data.data_type.unique())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['era1' 'era2' 'era3' 'era4' 'era5' 'era6' 'era7' 'era8' 'era9' 'era10'\n",
            " 'era11' 'era12' 'era13' 'era14' 'era15' 'era16' 'era17' 'era18' 'era19'\n",
            " 'era20' 'era21' 'era22' 'era23' 'era24' 'era25' 'era26' 'era27' 'era28'\n",
            " 'era29' 'era30' 'era31' 'era32' 'era33' 'era34' 'era35' 'era36' 'era37'\n",
            " 'era38' 'era39' 'era40' 'era41' 'era42' 'era43' 'era44' 'era45' 'era46'\n",
            " 'era47' 'era48' 'era49' 'era50' 'era51' 'era52' 'era53' 'era54' 'era55'\n",
            " 'era56' 'era57' 'era58' 'era59' 'era60' 'era61' 'era62' 'era63' 'era64'\n",
            " 'era65' 'era66' 'era67' 'era68' 'era69' 'era70' 'era71' 'era72' 'era73'\n",
            " 'era74' 'era75' 'era76' 'era77' 'era78' 'era79' 'era80' 'era81' 'era82'\n",
            " 'era83' 'era84' 'era85' 'era86' 'era87' 'era88' 'era89' 'era90' 'era91'\n",
            " 'era92' 'era93' 'era94' 'era95' 'era96' 'era97' 'era98' 'era99' 'era100'\n",
            " 'era101' 'era102' 'era103' 'era104' 'era105' 'era106' 'era107' 'era108'\n",
            " 'era109' 'era110' 'era111' 'era112' 'era113' 'era114' 'era115' 'era116'\n",
            " 'era117' 'era118' 'era119' 'era120']\n",
            "['train']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k20mt9ke7--E",
        "colab_type": "code",
        "outputId": "058cfb4b-ee13-4d14-8a6a-44dc1fcc5484",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "tournament_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>era</th>\n",
              "      <th>data_type</th>\n",
              "      <th>feature1</th>\n",
              "      <th>feature2</th>\n",
              "      <th>feature3</th>\n",
              "      <th>feature4</th>\n",
              "      <th>feature5</th>\n",
              "      <th>feature6</th>\n",
              "      <th>feature7</th>\n",
              "      <th>feature8</th>\n",
              "      <th>feature9</th>\n",
              "      <th>feature10</th>\n",
              "      <th>feature11</th>\n",
              "      <th>feature12</th>\n",
              "      <th>feature13</th>\n",
              "      <th>feature14</th>\n",
              "      <th>feature15</th>\n",
              "      <th>feature16</th>\n",
              "      <th>feature17</th>\n",
              "      <th>feature18</th>\n",
              "      <th>feature19</th>\n",
              "      <th>feature20</th>\n",
              "      <th>feature21</th>\n",
              "      <th>feature22</th>\n",
              "      <th>feature23</th>\n",
              "      <th>feature24</th>\n",
              "      <th>feature25</th>\n",
              "      <th>feature26</th>\n",
              "      <th>feature27</th>\n",
              "      <th>feature28</th>\n",
              "      <th>feature29</th>\n",
              "      <th>feature30</th>\n",
              "      <th>feature31</th>\n",
              "      <th>feature32</th>\n",
              "      <th>feature33</th>\n",
              "      <th>feature34</th>\n",
              "      <th>feature35</th>\n",
              "      <th>feature36</th>\n",
              "      <th>feature37</th>\n",
              "      <th>feature38</th>\n",
              "      <th>feature39</th>\n",
              "      <th>feature40</th>\n",
              "      <th>feature41</th>\n",
              "      <th>feature42</th>\n",
              "      <th>feature43</th>\n",
              "      <th>feature44</th>\n",
              "      <th>feature45</th>\n",
              "      <th>feature46</th>\n",
              "      <th>feature47</th>\n",
              "      <th>feature48</th>\n",
              "      <th>feature49</th>\n",
              "      <th>feature50</th>\n",
              "      <th>target_bernie</th>\n",
              "      <th>target_elizabeth</th>\n",
              "      <th>target_jordan</th>\n",
              "      <th>target_ken</th>\n",
              "      <th>target_charles</th>\n",
              "      <th>target_frank</th>\n",
              "      <th>target_hillary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>n00183d2eed2c463</td>\n",
              "      <td>era121</td>\n",
              "      <td>validation</td>\n",
              "      <td>0.48287</td>\n",
              "      <td>0.42120</td>\n",
              "      <td>0.43191</td>\n",
              "      <td>0.47676</td>\n",
              "      <td>0.66066</td>\n",
              "      <td>0.45914</td>\n",
              "      <td>0.64952</td>\n",
              "      <td>0.34748</td>\n",
              "      <td>0.46185</td>\n",
              "      <td>0.20546</td>\n",
              "      <td>0.49156</td>\n",
              "      <td>0.39329</td>\n",
              "      <td>0.39937</td>\n",
              "      <td>0.37417</td>\n",
              "      <td>0.58676</td>\n",
              "      <td>0.62827</td>\n",
              "      <td>0.79795</td>\n",
              "      <td>0.59824</td>\n",
              "      <td>0.54122</td>\n",
              "      <td>0.53318</td>\n",
              "      <td>0.25519</td>\n",
              "      <td>0.67109</td>\n",
              "      <td>0.51577</td>\n",
              "      <td>0.38332</td>\n",
              "      <td>0.45598</td>\n",
              "      <td>0.40689</td>\n",
              "      <td>0.68716</td>\n",
              "      <td>0.69627</td>\n",
              "      <td>0.52421</td>\n",
              "      <td>0.54837</td>\n",
              "      <td>0.40775</td>\n",
              "      <td>0.52625</td>\n",
              "      <td>0.24790</td>\n",
              "      <td>0.47168</td>\n",
              "      <td>0.54233</td>\n",
              "      <td>0.59809</td>\n",
              "      <td>0.68109</td>\n",
              "      <td>0.24670</td>\n",
              "      <td>0.72186</td>\n",
              "      <td>0.46969</td>\n",
              "      <td>0.50585</td>\n",
              "      <td>0.71507</td>\n",
              "      <td>0.47252</td>\n",
              "      <td>0.60217</td>\n",
              "      <td>0.33891</td>\n",
              "      <td>0.71388</td>\n",
              "      <td>0.50399</td>\n",
              "      <td>0.62938</td>\n",
              "      <td>0.42355</td>\n",
              "      <td>0.48586</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>n00187fa497c9d5b</td>\n",
              "      <td>era121</td>\n",
              "      <td>validation</td>\n",
              "      <td>0.51011</td>\n",
              "      <td>0.37615</td>\n",
              "      <td>0.32184</td>\n",
              "      <td>0.44538</td>\n",
              "      <td>0.45099</td>\n",
              "      <td>0.33395</td>\n",
              "      <td>0.72181</td>\n",
              "      <td>0.56949</td>\n",
              "      <td>0.46547</td>\n",
              "      <td>0.55405</td>\n",
              "      <td>0.54516</td>\n",
              "      <td>0.56209</td>\n",
              "      <td>0.35553</td>\n",
              "      <td>0.41724</td>\n",
              "      <td>0.57494</td>\n",
              "      <td>0.36404</td>\n",
              "      <td>0.41561</td>\n",
              "      <td>0.50075</td>\n",
              "      <td>0.67123</td>\n",
              "      <td>0.59919</td>\n",
              "      <td>0.31739</td>\n",
              "      <td>0.60887</td>\n",
              "      <td>0.40602</td>\n",
              "      <td>0.40601</td>\n",
              "      <td>0.55411</td>\n",
              "      <td>0.54181</td>\n",
              "      <td>0.46016</td>\n",
              "      <td>0.33375</td>\n",
              "      <td>0.44732</td>\n",
              "      <td>0.31876</td>\n",
              "      <td>0.39670</td>\n",
              "      <td>0.52094</td>\n",
              "      <td>0.42558</td>\n",
              "      <td>0.48726</td>\n",
              "      <td>0.58033</td>\n",
              "      <td>0.52757</td>\n",
              "      <td>0.64010</td>\n",
              "      <td>0.75350</td>\n",
              "      <td>0.59289</td>\n",
              "      <td>0.62679</td>\n",
              "      <td>0.45414</td>\n",
              "      <td>0.45149</td>\n",
              "      <td>0.61005</td>\n",
              "      <td>0.61914</td>\n",
              "      <td>0.61347</td>\n",
              "      <td>0.52267</td>\n",
              "      <td>0.57338</td>\n",
              "      <td>0.71008</td>\n",
              "      <td>0.57833</td>\n",
              "      <td>0.37761</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>n001acd04f3617b7</td>\n",
              "      <td>era121</td>\n",
              "      <td>validation</td>\n",
              "      <td>0.54132</td>\n",
              "      <td>0.50204</td>\n",
              "      <td>0.51473</td>\n",
              "      <td>0.36429</td>\n",
              "      <td>0.49878</td>\n",
              "      <td>0.34526</td>\n",
              "      <td>0.54342</td>\n",
              "      <td>0.40181</td>\n",
              "      <td>0.46430</td>\n",
              "      <td>0.26112</td>\n",
              "      <td>0.66008</td>\n",
              "      <td>0.52150</td>\n",
              "      <td>0.56858</td>\n",
              "      <td>0.36899</td>\n",
              "      <td>0.52793</td>\n",
              "      <td>0.66367</td>\n",
              "      <td>0.65544</td>\n",
              "      <td>0.50459</td>\n",
              "      <td>0.35391</td>\n",
              "      <td>0.58170</td>\n",
              "      <td>0.55619</td>\n",
              "      <td>0.60172</td>\n",
              "      <td>0.48668</td>\n",
              "      <td>0.52562</td>\n",
              "      <td>0.51202</td>\n",
              "      <td>0.37096</td>\n",
              "      <td>0.74306</td>\n",
              "      <td>0.59219</td>\n",
              "      <td>0.50593</td>\n",
              "      <td>0.36955</td>\n",
              "      <td>0.64996</td>\n",
              "      <td>0.53674</td>\n",
              "      <td>0.26698</td>\n",
              "      <td>0.25262</td>\n",
              "      <td>0.30420</td>\n",
              "      <td>0.53745</td>\n",
              "      <td>0.63324</td>\n",
              "      <td>0.38717</td>\n",
              "      <td>0.61095</td>\n",
              "      <td>0.30215</td>\n",
              "      <td>0.73956</td>\n",
              "      <td>0.50156</td>\n",
              "      <td>0.70121</td>\n",
              "      <td>0.58291</td>\n",
              "      <td>0.31697</td>\n",
              "      <td>0.49039</td>\n",
              "      <td>0.49569</td>\n",
              "      <td>0.69302</td>\n",
              "      <td>0.49393</td>\n",
              "      <td>0.42124</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>n0043a13252683ee</td>\n",
              "      <td>era121</td>\n",
              "      <td>validation</td>\n",
              "      <td>0.70262</td>\n",
              "      <td>0.34965</td>\n",
              "      <td>0.29921</td>\n",
              "      <td>0.35482</td>\n",
              "      <td>0.57076</td>\n",
              "      <td>0.43748</td>\n",
              "      <td>0.70020</td>\n",
              "      <td>0.64581</td>\n",
              "      <td>0.49447</td>\n",
              "      <td>0.45008</td>\n",
              "      <td>0.61966</td>\n",
              "      <td>0.61574</td>\n",
              "      <td>0.49037</td>\n",
              "      <td>0.46187</td>\n",
              "      <td>0.60667</td>\n",
              "      <td>0.39753</td>\n",
              "      <td>0.36893</td>\n",
              "      <td>0.57288</td>\n",
              "      <td>0.51000</td>\n",
              "      <td>0.48747</td>\n",
              "      <td>0.52571</td>\n",
              "      <td>0.56267</td>\n",
              "      <td>0.62027</td>\n",
              "      <td>0.41503</td>\n",
              "      <td>0.56818</td>\n",
              "      <td>0.37228</td>\n",
              "      <td>0.59793</td>\n",
              "      <td>0.33873</td>\n",
              "      <td>0.32437</td>\n",
              "      <td>0.39577</td>\n",
              "      <td>0.48824</td>\n",
              "      <td>0.76438</td>\n",
              "      <td>0.36478</td>\n",
              "      <td>0.44520</td>\n",
              "      <td>0.45292</td>\n",
              "      <td>0.52116</td>\n",
              "      <td>0.57084</td>\n",
              "      <td>0.79812</td>\n",
              "      <td>0.64330</td>\n",
              "      <td>0.58340</td>\n",
              "      <td>0.36657</td>\n",
              "      <td>0.41712</td>\n",
              "      <td>0.63159</td>\n",
              "      <td>0.55123</td>\n",
              "      <td>0.59608</td>\n",
              "      <td>0.52467</td>\n",
              "      <td>0.71556</td>\n",
              "      <td>0.53759</td>\n",
              "      <td>0.61071</td>\n",
              "      <td>0.39401</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>n00535e274720abd</td>\n",
              "      <td>era121</td>\n",
              "      <td>validation</td>\n",
              "      <td>0.71117</td>\n",
              "      <td>0.48561</td>\n",
              "      <td>0.47216</td>\n",
              "      <td>0.42956</td>\n",
              "      <td>0.41690</td>\n",
              "      <td>0.45130</td>\n",
              "      <td>0.60889</td>\n",
              "      <td>0.54193</td>\n",
              "      <td>0.42222</td>\n",
              "      <td>0.42162</td>\n",
              "      <td>0.48837</td>\n",
              "      <td>0.67109</td>\n",
              "      <td>0.47273</td>\n",
              "      <td>0.35398</td>\n",
              "      <td>0.66050</td>\n",
              "      <td>0.49083</td>\n",
              "      <td>0.40128</td>\n",
              "      <td>0.52134</td>\n",
              "      <td>0.66388</td>\n",
              "      <td>0.39145</td>\n",
              "      <td>0.32367</td>\n",
              "      <td>0.65308</td>\n",
              "      <td>0.66017</td>\n",
              "      <td>0.45059</td>\n",
              "      <td>0.35974</td>\n",
              "      <td>0.55754</td>\n",
              "      <td>0.66782</td>\n",
              "      <td>0.49589</td>\n",
              "      <td>0.59528</td>\n",
              "      <td>0.46147</td>\n",
              "      <td>0.43933</td>\n",
              "      <td>0.58362</td>\n",
              "      <td>0.43718</td>\n",
              "      <td>0.37612</td>\n",
              "      <td>0.55173</td>\n",
              "      <td>0.51210</td>\n",
              "      <td>0.49869</td>\n",
              "      <td>0.61266</td>\n",
              "      <td>0.70084</td>\n",
              "      <td>0.56393</td>\n",
              "      <td>0.43526</td>\n",
              "      <td>0.49275</td>\n",
              "      <td>0.44633</td>\n",
              "      <td>0.69448</td>\n",
              "      <td>0.61282</td>\n",
              "      <td>0.58780</td>\n",
              "      <td>0.56424</td>\n",
              "      <td>0.59359</td>\n",
              "      <td>0.33357</td>\n",
              "      <td>0.46400</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id     era  ... target_frank  target_hillary\n",
              "0  n00183d2eed2c463  era121  ...          0.0             0.0\n",
              "1  n00187fa497c9d5b  era121  ...          1.0             1.0\n",
              "2  n001acd04f3617b7  era121  ...          0.0             1.0\n",
              "3  n0043a13252683ee  era121  ...          0.0             0.0\n",
              "4  n00535e274720abd  era121  ...          0.0             0.0\n",
              "\n",
              "[5 rows x 60 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldZFWR027-6b",
        "colab_type": "code",
        "outputId": "1beefe81-2e21-4f56-c3f0-0e84ae61cac5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print(tournament_data.era.unique())\n",
        "print(tournament_data.data_type.unique())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['era121' 'era122' 'era123' 'era124' 'era125' 'era126' 'era127' 'era128'\n",
            " 'era129' 'era130' 'era131' 'era132' 'era133' 'era134' 'era135' 'era136'\n",
            " 'era137' 'era138' 'era139' 'era140' 'era141' 'era142' 'era143' 'era144'\n",
            " 'era145' 'era146' 'era147' 'era148' 'era149' 'era150' 'era151' 'era152'\n",
            " 'era153' 'era154' 'era155' 'era156' 'era157' 'era158' 'era159' 'era160'\n",
            " 'era161' 'era162' 'era163' 'era164' 'era165' 'era166' 'era167' 'era168'\n",
            " 'era169' 'era170' 'era171' 'era172' 'era173' 'era174' 'era175' 'era176'\n",
            " 'era177' 'era178' 'era179' 'era180' 'era181' 'era182' 'era183' 'era184'\n",
            " 'era185' 'era186' 'eraX']\n",
            "['validation' 'test' 'live']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKgMl9M47-3l",
        "colab_type": "code",
        "outputId": "679d2820-ae7e-4dc5-c573-8388be1bdcad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print(tournament_data.era[tournament_data.data_type=='validation'].unique())\n",
        "print(tournament_data.era[tournament_data.data_type=='test'].unique())\n",
        "print(tournament_data.era[tournament_data.data_type=='live'].unique())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['era121' 'era122' 'era123' 'era124' 'era125' 'era126' 'era127' 'era128'\n",
            " 'era129' 'era130' 'era131' 'era132']\n",
            "['era133' 'era134' 'era135' 'era136' 'era137' 'era138' 'era139' 'era140'\n",
            " 'era141' 'era142' 'era143' 'era144' 'era145' 'era146' 'era147' 'era148'\n",
            " 'era149' 'era150' 'era151' 'era152' 'era153' 'era154' 'era155' 'era156'\n",
            " 'era157' 'era158' 'era159' 'era160' 'era161' 'era162' 'era163' 'era164'\n",
            " 'era165' 'era166' 'era167' 'era168' 'era169' 'era170' 'era171' 'era172'\n",
            " 'era173' 'era174' 'era175' 'era176' 'era177' 'era178' 'era179' 'era180'\n",
            " 'era181' 'era182' 'era183' 'era184' 'era185' 'era186']\n",
            "['eraX']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a89qSCbP7-0T",
        "colab_type": "code",
        "outputId": "a78a3a80-1944-4ba3-9da9-f9f4bfe16fd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(tournament_data.target_hillary\n",
        "[tournament_data.data_type=='validation'].unique())\n",
        "print(tournament_data.target_hillary\n",
        "[tournament_data.data_type=='test'].unique())\n",
        "print(tournament_data.target_hillary\n",
        "[tournament_data.data_type=='live'].unique())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 1.]\n",
            "[nan]\n",
            "[nan]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxOuFxN07-w8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_data = tournament_data[tournament_data.data_type=='validation']\n",
        "complete_training_data = pd.concat([training_data,validation_data])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFBJwE8Z7-uA",
        "colab_type": "code",
        "outputId": "62969901-ca34-4852-d53e-766c3ae1581b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "complete_training_data.era.unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['era1', 'era2', 'era3', 'era4', 'era5', 'era6', 'era7', 'era8',\n",
              "       'era9', 'era10', 'era11', 'era12', 'era13', 'era14', 'era15',\n",
              "       'era16', 'era17', 'era18', 'era19', 'era20', 'era21', 'era22',\n",
              "       'era23', 'era24', 'era25', 'era26', 'era27', 'era28', 'era29',\n",
              "       'era30', 'era31', 'era32', 'era33', 'era34', 'era35', 'era36',\n",
              "       'era37', 'era38', 'era39', 'era40', 'era41', 'era42', 'era43',\n",
              "       'era44', 'era45', 'era46', 'era47', 'era48', 'era49', 'era50',\n",
              "       'era51', 'era52', 'era53', 'era54', 'era55', 'era56', 'era57',\n",
              "       'era58', 'era59', 'era60', 'era61', 'era62', 'era63', 'era64',\n",
              "       'era65', 'era66', 'era67', 'era68', 'era69', 'era70', 'era71',\n",
              "       'era72', 'era73', 'era74', 'era75', 'era76', 'era77', 'era78',\n",
              "       'era79', 'era80', 'era81', 'era82', 'era83', 'era84', 'era85',\n",
              "       'era86', 'era87', 'era88', 'era89', 'era90', 'era91', 'era92',\n",
              "       'era93', 'era94', 'era95', 'era96', 'era97', 'era98', 'era99',\n",
              "       'era100', 'era101', 'era102', 'era103', 'era104', 'era105',\n",
              "       'era106', 'era107', 'era108', 'era109', 'era110', 'era111',\n",
              "       'era112', 'era113', 'era114', 'era115', 'era116', 'era117',\n",
              "       'era118', 'era119', 'era120', 'era121', 'era122', 'era123',\n",
              "       'era124', 'era125', 'era126', 'era127', 'era128', 'era129',\n",
              "       'era130', 'era131', 'era132'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG_1eu4i7-qu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = [f for f in list(complete_training_data) if \"feature\" in f]\n",
        "X = complete_training_data[features]\n",
        "Y = complete_training_data[\"target_hillary\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6y9GZMT7-ng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4tgkZUm7-iz",
        "colab_type": "code",
        "outputId": "91f2a474-269f-4d81-b62c-d949d488dd79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(X.shape,Y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(558816, 50) (558816,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Il0huQeX7-eQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size=0.5, train_size=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tD7RqOq-7-aL",
        "colab_type": "code",
        "outputId": "9df8d657-c2f2-4e3c-946e-587137de1d66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1105
        }
      },
      "source": [
        "print(X_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        feature1  feature2  feature3  ...  feature48  feature49  feature50\n",
            "491117   0.37158   0.38091   0.42680  ...    0.69206    0.71391    0.75060\n",
            "382078   0.29837   0.46993   0.52137  ...    0.44326    0.50655    0.44880\n",
            "71638    0.64688   0.38540   0.57367  ...    0.53956    0.60663    0.47894\n",
            "49057    0.25032   0.46223   0.70829  ...    0.53090    0.59887    0.61243\n",
            "19824    0.44274   0.62552   0.37176  ...    0.43796    0.42276    0.47490\n",
            "44137    0.31655   0.37353   0.57360  ...    0.41442    0.51272    0.73585\n",
            "263043   0.60950   0.30627   0.41023  ...    0.38434    0.39334    0.44772\n",
            "479955   0.48660   0.38437   0.47464  ...    0.52650    0.39911    0.34409\n",
            "83890    0.43777   0.50364   0.62954  ...    0.36210    0.54077    0.61389\n",
            "299906   0.43744   0.38243   0.44199  ...    0.50338    0.71266    0.66091\n",
            "362931   0.22465   0.59554   0.37751  ...    0.48328    0.61972    0.42636\n",
            "43328    0.31173   0.58654   0.55711  ...    0.38444    0.47435    0.47917\n",
            "10347    0.35594   0.44955   0.44875  ...    0.41674    0.43150    0.41895\n",
            "248809   0.70538   0.31299   0.27944  ...    0.46507    0.42748    0.60945\n",
            "22677    0.55499   0.44173   0.46241  ...    0.39537    0.39530    0.53980\n",
            "313064   0.35242   0.65622   0.42618  ...    0.45432    0.45477    0.43996\n",
            "31617    0.41284   0.46009   0.69736  ...    0.46253    0.53919    0.59692\n",
            "170016   0.47746   0.37012   0.37990  ...    0.77951    0.49962    0.49544\n",
            "43845    0.56875   0.49549   0.44582  ...    0.29420    0.49133    0.53313\n",
            "393498   0.58720   0.35146   0.27549  ...    0.74033    0.47252    0.43973\n",
            "68548    0.60163   0.30450   0.48923  ...    0.69715    0.54184    0.58389\n",
            "34508    0.51595   0.27395   0.53664  ...    0.80973    0.50981    0.65817\n",
            "375700   0.31114   0.29547   0.49944  ...    0.44687    0.49272    0.57459\n",
            "40610    0.42931   0.36871   0.48038  ...    0.42158    0.51122    0.52223\n",
            "438660   0.44322   0.25438   0.17454  ...    0.65187    0.67450    0.58975\n",
            "232467   0.47993   0.55400   0.56232  ...    0.32050    0.43253    0.62193\n",
            "402746   0.43983   0.60635   0.51997  ...    0.31959    0.57653    0.59138\n",
            "49495    0.63190   0.52888   0.42926  ...    0.63369    0.53161    0.36080\n",
            "203658   0.29143   0.35252   0.59146  ...    0.60858    0.68959    0.48358\n",
            "82689    0.81451   0.41379   0.41945  ...    0.61814    0.57108    0.64356\n",
            "...          ...       ...       ...  ...        ...        ...        ...\n",
            "357384   0.56248   0.40673   0.47487  ...    0.64665    0.45527    0.65513\n",
            "47878    0.60951   0.56067   0.41991  ...    0.57350    0.50856    0.53053\n",
            "55694    0.40950   0.49889   0.42378  ...    0.50130    0.36904    0.58149\n",
            "29545    0.45563   0.48396   0.48534  ...    0.38875    0.40869    0.36072\n",
            "341190   0.39129   0.49078   0.60135  ...    0.54688    0.57841    0.58578\n",
            "196682   0.59240   0.43446   0.52736  ...    0.38867    0.37989    0.46870\n",
            "402468   0.59418   0.40393   0.43636  ...    0.62274    0.54260    0.54730\n",
            "218907   0.53635   0.61227   0.62931  ...    0.64306    0.40309    0.56329\n",
            "16082    0.44229   0.27292   0.36471  ...    0.44482    0.55651    0.56383\n",
            "166380   0.59115   0.40994   0.66773  ...    0.55464    0.44774    0.42771\n",
            "410888   0.48471   0.44663   0.55221  ...    0.48853    0.58773    0.48587\n",
            "164240   0.45823   0.54044   0.62407  ...    0.45356    0.55117    0.40589\n",
            "452493   0.61341   0.53386   0.47680  ...    0.72366    0.51496    0.74851\n",
            "385493   0.48680   0.31262   0.41323  ...    0.43575    0.51716    0.61588\n",
            "483356   0.54473   0.60618   0.42101  ...    0.58499    0.39946    0.57660\n",
            "109481   0.39245   0.51844   0.20374  ...    0.44254    0.54810    0.46983\n",
            "143414   0.75378   0.36208   0.51959  ...    0.50400    0.44876    0.43162\n",
            "82330    0.51384   0.35254   0.35819  ...    0.52884    0.70615    0.63654\n",
            "99532    0.39531   0.51647   0.37203  ...    0.62632    0.56280    0.46172\n",
            "285054   0.53273   0.47185   0.25891  ...    0.64300    0.51429    0.51708\n",
            "341971   0.64163   0.41190   0.62633  ...    0.57130    0.34774    0.66064\n",
            "221522   0.27697   0.53220   0.44640  ...    0.43653    0.53968    0.60029\n",
            "495256   0.59641   0.39988   0.38622  ...    0.80660    0.67269    0.55284\n",
            "146324   0.47511   0.38335   0.38551  ...    0.46454    0.49286    0.46745\n",
            "338640   0.33732   0.64585   0.63467  ...    0.45509    0.50811    0.39046\n",
            "23403    0.59848   0.46338   0.34602  ...    0.54473    0.42726    0.51887\n",
            "265297   0.71631   0.49737   0.35240  ...    0.50928    0.52687    0.58464\n",
            "68462    0.40113   0.39411   0.44142  ...    0.60131    0.51115    0.60088\n",
            "74539    0.42370   0.41887   0.51825  ...    0.38806    0.41587    0.57752\n",
            "13923    0.18970   0.67252   0.70409  ...    0.47543    0.49026    0.61586\n",
            "\n",
            "[279408 rows x 50 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evsRN9TB7-L5",
        "colab_type": "code",
        "outputId": "9f08c247-ae66-42ba-c887-c79a4b96e1f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1071
        }
      },
      "source": [
        "print(y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "491117    1.0\n",
            "382078    0.0\n",
            "71638     0.0\n",
            "49057     1.0\n",
            "19824     0.0\n",
            "44137     1.0\n",
            "263043    0.0\n",
            "479955    1.0\n",
            "83890     1.0\n",
            "299906    0.0\n",
            "362931    1.0\n",
            "43328     0.0\n",
            "10347     0.0\n",
            "248809    0.0\n",
            "22677     0.0\n",
            "313064    0.0\n",
            "31617     0.0\n",
            "170016    1.0\n",
            "43845     0.0\n",
            "393498    1.0\n",
            "68548     0.0\n",
            "34508     1.0\n",
            "375700    1.0\n",
            "40610     0.0\n",
            "438660    1.0\n",
            "232467    0.0\n",
            "402746    0.0\n",
            "49495     0.0\n",
            "203658    1.0\n",
            "82689     1.0\n",
            "         ... \n",
            "357384    1.0\n",
            "47878     0.0\n",
            "55694     1.0\n",
            "29545     1.0\n",
            "341190    0.0\n",
            "196682    0.0\n",
            "402468    1.0\n",
            "218907    0.0\n",
            "16082     0.0\n",
            "166380    1.0\n",
            "410888    0.0\n",
            "164240    0.0\n",
            "452493    0.0\n",
            "385493    1.0\n",
            "483356    1.0\n",
            "109481    0.0\n",
            "143414    0.0\n",
            "82330     1.0\n",
            "99532     1.0\n",
            "285054    0.0\n",
            "341971    1.0\n",
            "221522    1.0\n",
            "495256    0.0\n",
            "146324    1.0\n",
            "338640    1.0\n",
            "23403     1.0\n",
            "265297    1.0\n",
            "68462     0.0\n",
            "74539     0.0\n",
            "13923     0.0\n",
            "Name: target_hillary, Length: 279408, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsC4BO-S79xu",
        "colab_type": "code",
        "outputId": "5bd2139a-d871-4b60-dbbf-0a6cca3d3e47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "Y.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1.0\n",
              "1    1.0\n",
              "2    0.0\n",
              "3    0.0\n",
              "4    1.0\n",
              "Name: target_hillary, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRMAmd2hqgpM",
        "colab_type": "code",
        "outputId": "3fc09e63-57b8-40a7-8b78-e228676dada3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, BatchNormalization, Dropout, Activation\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VflxSFgc8t6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Performing Predictions with Keras and scikit-learn\n",
        "\n",
        "def create_model(neurons=200, dropout=0.2):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(neurons, input_shape=(50,), kernel_initializer='glorot_uniform', use_bias=False))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(1, activation='sigmoid', kernel_initializer='glorot_normal'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_crossentropy', 'accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQQ2iAwb8tuc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = KerasClassifier(build_fn=create_model, epochs=8, batch_size=128, verbose=0)         "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1Zjf4w-8tjx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gkf = GroupKFold(n_splits=5)\n",
        "kfold_split = gkf.split(X, Y, groups=complete_training_data.era)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0or4uds87Ds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neurons = [10, 14]  \n",
        "dropout = [0.01, 0.28]    \n",
        "param_grid = dict(neurons=neurons, dropout=dropout)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTaheEiU86_R",
        "colab_type": "code",
        "outputId": "4f65ebbf-c85b-4e75-c5e6-8ebce47b55df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1125
        }
      },
      "source": [
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=kfold_split, scoring='neg_log_loss',n_jobs=1, verbose=3)\n",
        "grid_result = grid.fit(X.values, Y.values)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "[CV] dropout=0.01, neurons=10 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0616 12:49:24.294397 140052944226176 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0616 12:49:24.309043 140052944226176 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0616 12:49:24.311776 140052944226176 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0616 12:49:24.387420 140052944226176 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0616 12:49:24.411809 140052944226176 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0616 12:49:24.425971 140052944226176 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "W0616 12:49:24.439920 140052944226176 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0616 12:49:24.461965 140052944226176 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ........... dropout=0.01, neurons=10, score=-0.692, total= 1.9min\n",
            "[CV] dropout=0.01, neurons=10 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.9min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ........... dropout=0.01, neurons=10, score=-0.692, total= 1.9min\n",
            "[CV] dropout=0.01, neurons=10 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  3.9min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ........... dropout=0.01, neurons=10, score=-0.693, total= 2.0min\n",
            "[CV] dropout=0.01, neurons=10 ........................................\n",
            "[CV] ........... dropout=0.01, neurons=10, score=-0.693, total= 1.9min\n",
            "[CV] dropout=0.01, neurons=10 ........................................\n",
            "[CV] ........... dropout=0.01, neurons=10, score=-0.693, total= 2.0min\n",
            "[CV] dropout=0.01, neurons=14 ........................................\n",
            "[CV] ........... dropout=0.01, neurons=14, score=-0.692, total= 2.0min\n",
            "[CV] dropout=0.01, neurons=14 ........................................\n",
            "[CV] ........... dropout=0.01, neurons=14, score=-0.693, total= 2.0min\n",
            "[CV] dropout=0.01, neurons=14 ........................................\n",
            "[CV] ........... dropout=0.01, neurons=14, score=-0.693, total= 2.0min\n",
            "[CV] dropout=0.01, neurons=14 ........................................\n",
            "[CV] ........... dropout=0.01, neurons=14, score=-0.693, total= 2.0min\n",
            "[CV] dropout=0.01, neurons=14 ........................................\n",
            "[CV] ........... dropout=0.01, neurons=14, score=-0.692, total= 2.0min\n",
            "[CV] dropout=0.28, neurons=10 ........................................\n",
            "[CV] ........... dropout=0.28, neurons=10, score=-0.692, total= 2.0min\n",
            "[CV] dropout=0.28, neurons=10 ........................................\n",
            "[CV] ........... dropout=0.28, neurons=10, score=-0.692, total= 2.0min\n",
            "[CV] dropout=0.28, neurons=10 ........................................\n",
            "[CV] ........... dropout=0.28, neurons=10, score=-0.693, total= 2.0min\n",
            "[CV] dropout=0.28, neurons=10 ........................................\n",
            "[CV] ........... dropout=0.28, neurons=10, score=-0.693, total= 2.0min\n",
            "[CV] dropout=0.28, neurons=10 ........................................\n",
            "[CV] ........... dropout=0.28, neurons=10, score=-0.692, total= 2.0min\n",
            "[CV] dropout=0.28, neurons=14 ........................................\n",
            "[CV] ........... dropout=0.28, neurons=14, score=-0.692, total= 2.0min\n",
            "[CV] dropout=0.28, neurons=14 ........................................\n",
            "[CV] ........... dropout=0.28, neurons=14, score=-0.692, total= 2.0min\n",
            "[CV] dropout=0.28, neurons=14 ........................................\n",
            "[CV] ........... dropout=0.28, neurons=14, score=-0.693, total= 2.1min\n",
            "[CV] dropout=0.28, neurons=14 ........................................\n",
            "[CV] ........... dropout=0.28, neurons=14, score=-0.693, total= 2.0min\n",
            "[CV] dropout=0.28, neurons=14 ........................................\n",
            "[CV] ........... dropout=0.28, neurons=14, score=-0.693, total= 2.1min\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed: 39.9min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDUHCNej867k",
        "colab_type": "code",
        "outputId": "fd3d027f-c73a-42ae-fe7e-abf07cd04cab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: -0.692477 using {'dropout': 0.28, 'neurons': 10}\n",
            "-0.692521 (0.000218) with: {'dropout': 0.01, 'neurons': 10}\n",
            "-0.692513 (0.000254) with: {'dropout': 0.01, 'neurons': 14}\n",
            "-0.692477 (0.000201) with: {'dropout': 0.28, 'neurons': 10}\n",
            "-0.692555 (0.000221) with: {'dropout': 0.28, 'neurons': 14}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIKG4Pgc863i",
        "colab_type": "code",
        "outputId": "9c50d91d-80bc-4913-ac34-993e6ac0c5f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "#Checking the Performance\n",
        "\n",
        "def check_consistency(model, valid_data):\n",
        "    eras = valid_data.era.unique()\n",
        "    count = 0\n",
        "    count_consistent = 0\n",
        "    for era in eras:\n",
        "        count += 1\n",
        "        current_valid_data = valid_data[validation_data.era==era]\n",
        "        features = [f for f in list(complete_training_data) if \"feature\" in f]\n",
        "        X_valid = current_valid_data[features]\n",
        "        Y_valid = current_valid_data[\"target_hillary\"]\n",
        "        loss = model.evaluate(X_valid.values, Y_valid.values, batch_size=128, verbose=0)[0]\n",
        "        if (loss < -np.log(.5)):\n",
        "            consistent = True\n",
        "            count_consistent += 1\n",
        "        else:\n",
        "            consistent = False\n",
        "        print(\"{}: loss - {} consistent: {}\".format(era, loss, consistent))\n",
        "    print (\"Consistency: {}\".format(count_consistent/count))\n",
        "        \n",
        "\n",
        "check_consistency(grid.best_estimator_.model, validation_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "era121: loss - 0.6939357558536109 consistent: False\n",
            "era122: loss - 0.6913683531967737 consistent: True\n",
            "era123: loss - 0.6923223554385588 consistent: True\n",
            "era124: loss - 0.691154286304212 consistent: True\n",
            "era125: loss - 0.6927967652911271 consistent: True\n",
            "era126: loss - 0.6922725060582801 consistent: True\n",
            "era127: loss - 0.6938731253593363 consistent: False\n",
            "era128: loss - 0.6924637349158371 consistent: True\n",
            "era129: loss - 0.6919941492655362 consistent: True\n",
            "era130: loss - 0.6917819302491467 consistent: True\n",
            "era131: loss - 0.6914339367225256 consistent: True\n",
            "era132: loss - 0.6918372036836885 consistent: True\n",
            "Consistency: 0.8333333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvbXdywI86zQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Submitting the Predictions\n",
        "import time\n",
        "\n",
        "x_prediction = tournament_data[features]\n",
        "t_id = tournament_data[\"id\"]\n",
        "y_prediction = grid.best_estimator_.model.predict_proba(x_prediction.values, batch_size=128)\n",
        "results = np.reshape(y_prediction,-1)\n",
        "results_df = pd.DataFrame(data={'probability_hillary':results})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgRn4ace86vN",
        "colab_type": "code",
        "outputId": "8833b5b3-f6cf-4449-ee41-c19df9e4c376",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "joined = pd.DataFrame(t_id).join(results_df)\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw__U8Rs86jD",
        "colab_type": "code",
        "outputId": "1fe511c0-c85c-47fb-8c76-e16dd3381f0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from time import gmtime, strftime\n",
        "strftime(\"%a, %d %b %Y %H:%M:%S +0000\", gmtime())\n",
        "joined = pd.DataFrame(t_id).join(results_df)\n",
        "# path = \"predictions_w_loss_0_\" + '{:4.0f}'.format(history.history['loss'][-1]*10000) + \".csv\"\n",
        "path = 'predictions_{:}'.format(strftime(\"%Y-%m-%d_%Hh%Mm%Ss\", time.gmtime())) + '.csv'\n",
        "print()\n",
        "print(\"Writing predictions to \" + path.strip())\n",
        "# # Save the predictions out to a CSV file\n",
        "joined.to_csv(path,float_format='%.15f', index=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Writing predictions to predictions_2019-06-16_13h32m03s.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTdDM2s8HaFu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}